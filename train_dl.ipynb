{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e8a773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorly in c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly) (1.23.5)\n",
      "Requirement already satisfied: nose in c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly) (1.3.7)\n",
      "Requirement already satisfied: scipy in c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorly) (1.10.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opencv-python) (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 22.3.1 from C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip (python 3.9)\n",
      "Collecting tensorly==0.7.0\n",
      "  Using cached tensorly-0.7.0-py3-none-any.whl (198 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.10.1-cp39-cp39-win_amd64.whl (42.5 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Collecting nose\n",
      "  Using cached nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "Installing collected packages: nose, numpy, scipy, tensorly\n",
      "  Attempting uninstall: nose\n",
      "    Found existing installation: nose 1.3.7\n",
      "    Uninstalling nose-1.3.7:\n",
      "      Removing file or directory c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nose-1.3.7.dist-info\\\n",
      "      Removing file or directory c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nose\\\n",
      "      Removing file or directory c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\man\\man1\\\n",
      "      Removing file or directory c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\scripts\\nosetests-3.4.exe\n",
      "      Removing file or directory c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\scripts\\nosetests.exe\n",
      "      Successfully uninstalled nose-1.3.7\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Removing file or directory c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy-1.23.5.dist-info\\\n",
      "      Removing file or directory c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\\n",
      "      Removing file or directory c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\scripts\\f2py.exe\n",
      "      Successfully uninstalled numpy-1.23.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError.\n",
      "Consider using the `--user` option or check the permissions.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 494, in run\n",
      "    installed = install_given_reqs(\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\req\\__init__.py\", line 90, in install_given_reqs\n",
      "    uninstalled_pathset.commit()\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py\", line 424, in commit\n",
      "    self._moved_paths.commit()\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py\", line 277, in commit\n",
      "    save_dir.cleanup()\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 173, in cleanup\n",
      "    rmtree(self._path)\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 328, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 408, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 364, in iter\n",
      "    raise retry_exc.reraise()\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 197, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\", line 439, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 411, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 128, in rmtree\n",
      "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\shutil.py\", line 759, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\shutil.py\", line 624, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\shutil.py\", line 629, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\shutil.py\", line 627, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] \\u041e\\u0442\\u043a\\u0430\\u0437\\u0430\\u043d\\u043e \\u0432 \\u0434\\u043e\\u0441\\u0442\\u0443\\u043f\\u0435: 'C:\\\\Users\\\\nelli\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\Lib\\\\site-packages\\\\~7mpy\\\\.libs\\\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll'\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 22.3.1 from C:\\Users\\nelli\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip (python 3.9)\n",
      "Collecting numpy==1.23.5\n",
      "  Using cached numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Removing file or directory c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy-1.24.3.dist-info\\\n",
      "      Removing file or directory c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\\n",
      "      Removing file or directory c:\\users\\nelli\\appdata\\local\\programs\\python\\python39\\scripts\\f2py.exe\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed numpy-1.23.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.1 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.9.24 which is incompatible.\n",
      "tensorflow 2.9.1 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 2.10.0 which is incompatible.\n",
      "tensorflow-gpu 2.9.1 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.9.24 which is incompatible.\n",
      "tensorflow-gpu 2.9.1 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 2.10.0 which is incompatible.\n",
      "numba 0.55.2 requires numpy<1.23,>=1.18, but you have numpy 1.23.5 which is incompatible.\n",
      "flwr 0.19.0 requires numpy<1.21.0,>=1.19.0; python_version < \"3.10\", but you have numpy 1.23.5 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorly\n",
    "!pip install opencv-python\n",
    "!pip install --force-reinstall -v \"tensorly==0.7.0\"\n",
    "!pip install --force-reinstall -v \"numpy==1.23.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde68542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Type\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.misc\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import tensorly as tl\n",
    "import numpy as np\n",
    "from sklearn.linear_model import orthogonal_mp\n",
    "from tensorly.decomposition import tucker, partial_tucker\n",
    "from sklearn.feature_extraction.image import extract_patches_2d, reconstruct_from_patches_2d\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b101da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pursuit:\n",
    "    \"\"\"\n",
    "    Algorithms that inherit from this class are methods to solve problems of the like\n",
    "    \\min_A \\| DA - Y \\|_2 s.t. \\|A\\|_0 <= t.\n",
    "    Here, D is a given dictionary of size (n x K)\n",
    "    Y is a given matrix of size (n x N), where N is the number of samples\n",
    "    The Pursuit will return a matrix A of size (K x N).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dictionary, max_iter=False, tol=None, sparsity=None):\n",
    "        self.D = np.array(dictionary.matrix)\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.sparsity = sparsity\n",
    "        if (self.tol is None and self.sparsity is None) or (self.tol is not None and self.sparsity is not None):\n",
    "            raise ValueError(\"blub\")\n",
    "        self.data = None\n",
    "        self.alphas = []\n",
    "\n",
    "    def fit(self, Y):\n",
    "        return [], self.alphas\n",
    "\n",
    "\n",
    "class OrthogonalMatchingPursuit(Pursuit):\n",
    "    \"\"\"\n",
    "    Wrapper for orthogonal_mp from scikit-learn\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, Y):\n",
    "        return orthogonal_mp(self.D, Y, n_nonzero_coefs=self.sparsity,\n",
    "                             tol=self.tol, precompute=True)\n",
    "\n",
    "    \n",
    "class Dictionary:\n",
    "    \"\"\"\n",
    "    The Dictionary class is more or less a wrapper around the numpy array class. It holds a numpy ndarray in\n",
    "    the attribute `matrix` and adds some useful functions for it. The dictionary elements can be accessed\n",
    "    either by D.matrix[i,j] or directly through D[i,j].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, matrix):\n",
    "        self.matrix = np.array(matrix)\n",
    "        self.shape = matrix.shape\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.matrix[item]\n",
    "\n",
    "    def is_unitary(self):\n",
    "        \"\"\"\n",
    "        Checks whether the dictionary is unitary.\n",
    "        Returns:\n",
    "            True, if the dicitonary is unitary.\n",
    "        \"\"\"\n",
    "        n, K = self.shape\n",
    "        if n == K:\n",
    "            return np.allclose(np.dot(self.matrix.T, self.matrix), np.eye(n))\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_normalized(self):\n",
    "        \"\"\"\n",
    "        Checks wheter the dictionary is l2-normalized.\n",
    "        Returns:\n",
    "            True, if dictionary is l2-normalized.\n",
    "        \"\"\"\n",
    "        n, K = self.shape\n",
    "        return np.allclose([np.linalg.norm(self.matrix[:, i]) for i in range(K)], np.ones(K))\n",
    "\n",
    "\n",
    "    def mutual_coherence(self):\n",
    "        \"\"\"\n",
    "        Computes the dictionary's mutual coherence.\n",
    "        Returns:\n",
    "            Mutual coherence\n",
    "        \"\"\"\n",
    "        return np.max(self._mutual_coherence(self.matrix))\n",
    "\n",
    "    @staticmethod\n",
    "    def _mutual_coherence(D):\n",
    "        n, K = D.shape\n",
    "        mu = [np.abs(np.dot(D[:, i].T, D[:, j]) /\n",
    "                     (np.linalg.norm(D[:, i]) * np.linalg.norm(D[:, j])))\n",
    "              for i in range(K) for j in range(K) if j != i]\n",
    "        return mu\n",
    "\n",
    "    def to_img(self):\n",
    "        \"\"\"\n",
    "        Transforms the dictionary columns into patches and orders them for plotting purposes.\n",
    "        Returns:\n",
    "            Reordered dictionary matrix\n",
    "        \"\"\"\n",
    "        # dictionary dimensions\n",
    "        D = self.matrix\n",
    "        n, K = D.shape\n",
    "        M = self.matrix\n",
    "        # stretch atoms\n",
    "        for k in range(K):\n",
    "            M[:, k] = M[:, k] - (M[:, k].min())\n",
    "            if M[:, k].max():\n",
    "                M[:, k] = M[:, k] / D[:, k].max()\n",
    "\n",
    "        # patch size\n",
    "        n_r = int(np.sqrt(n))\n",
    "\n",
    "        # patches per row / column\n",
    "        K_r = int(np.sqrt(K))\n",
    "\n",
    "        # we need n_r*K_r+K_r+1 pixels in each direction\n",
    "        dim = n_r * K_r + K_r + 1\n",
    "        V = np.ones((dim, dim)) * np.min(D)\n",
    "\n",
    "        # compute the patches\n",
    "        patches = [np.reshape(D[:, i], (n_r, n_r)) for i in range(K)]\n",
    "\n",
    "        # place patches\n",
    "        for i in range(K_r):\n",
    "            for j in range(K_r):\n",
    "                V[j * n_r + 1 + j:(j + 1) * n_r + 1 + j, i * n_r + 1 + i:(i + 1) * n_r + 1 + i] = patches[\n",
    "                    i * K_r + j]\n",
    "        return V\n",
    "\n",
    "\n",
    "class KSVD:\n",
    "    \"\"\"\n",
    "    Implements the original K-SVD Algorithm as described in [1].\n",
    "    [1] Aharon, M., Elad, M. and Bruckstein, A., 2006. K-SVD: An algorithm for designing overcomplete dictionaries for\n",
    "        sparse representation. IEEE Transactions on signal processing, 54(11), p.4311.\n",
    "    Args:\n",
    "        dictionary: Initial dictionary of type sparselandtools.dictionaries.Dictionary\n",
    "        pursuit: Pursuit method to be used (any method from sparselandtools.pursuits)\n",
    "        sparsity: Target sparsity\n",
    "        noise_gain: Target noise_gain. If set, this will override the target sparsity\n",
    "        sigma: Signal or image noise standard deviation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dictionary: Dictionary, pursuit: Type[Pursuit], sparsity: int, noise_gain=None, sigma=None):\n",
    "        self.dictionary = Dictionary(dictionary.matrix)\n",
    "        self.alphas = None\n",
    "        self.pursuit = pursuit\n",
    "        self.sparsity = sparsity\n",
    "        self.noise_gain = noise_gain\n",
    "        self.sigma = sigma\n",
    "        self.original_image = None\n",
    "        self.sparsity_values = []\n",
    "        self.mses = []\n",
    "        self.ssims = []\n",
    "        self.psnrs = []\n",
    "        self.iter = None\n",
    "\n",
    "    def sparse_coding(self, Y: np.ndarray):\n",
    "        logging.info(\"Entering sparse coding stage...\")\n",
    "        if self.noise_gain and self.sigma:\n",
    "            p = self.pursuit(self.dictionary, tol=(self.noise_gain * self.sigma))\n",
    "        else:\n",
    "            p = self.pursuit(self.dictionary, sparsity=self.sparsity)\n",
    "        self.alphas = p.fit(Y)\n",
    "        logging.info(\"Sparse coding stage ended.\")\n",
    "\n",
    "    def dictionary_update(self, Y: np.ndarray):\n",
    "        # iterate rows\n",
    "        D = self.dictionary.matrix\n",
    "        n, K = D.shape\n",
    "        R = Y - D.dot(self.alphas)\n",
    "        for k in range(K):\n",
    "            logging.info(\"Updating column %s\" % k)\n",
    "            wk = np.nonzero(self.alphas[k, :])[0]\n",
    "            if len(wk) == 0:\n",
    "                continue\n",
    "            Ri = R[:,wk] + D[:,k,None].dot(self.alphas[None,k,wk])\n",
    "            U, s, Vh = np.linalg.svd(Ri)\n",
    "            D[:, k] = U[:, 0]\n",
    "            self.alphas[k, wk] = s[0] * Vh[0, :]\n",
    "            R[:, wk] = Ri - D[:,k,None].dot(self.alphas[None,k,wk])\n",
    "        self.dictionary = Dictionary(D)\n",
    "\n",
    "    def fit(self, Y: np.ndarray, iter: int):\n",
    "        for i in range(iter):\n",
    "            logging.info(\"Start iteration %s\" % (i + 1))\n",
    "            self.sparse_coding(Y)\n",
    "            self.dictionary_update(Y)\n",
    "        return self.dictionary, self.alphas\n",
    "\n",
    "\n",
    "def preprocess(image):\n",
    "    core, factors = partial_tucker(tl.tensor(image), rank=image.shape, modes=[0, 1, 2])\n",
    "    return factors[0]\n",
    "\n",
    "\n",
    "def get_matrix(y, image_path, patch_size):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    component = preprocess(image)\n",
    "    \n",
    "    # Extract all reference patches from the image\n",
    "    patches = extract_patches_2d(component, (patch_size, patch_size))\n",
    "    data = patches.reshape(patches.shape[0], -1)\n",
    "    y = np.vstack([y, data])\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e527ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = 'images_test_b'\n",
    "image_paths = glob(os.path.join(image_directory, '*.png'))\n",
    "from random import shuffle\n",
    "shuffle(image_paths)\n",
    "\n",
    "patch_size = 4 ########\n",
    "\n",
    "y = np.zeros(patch_size * patch_size)\n",
    "for image_path in image_paths:\n",
    "    y = get_matrix(y, image_path, patch_size)\n",
    "y = np.delete(y, 0, axis=0)\n",
    "test = y.T\n",
    "u, s, v = np.linalg.svd(test)\n",
    "initial_dictionary = Dictionary(u)\n",
    "ksvd = KSVD(initial_dictionary, OrthogonalMatchingPursuit, 16)\n",
    "learn_dict, coeff = ksvd.fit(test, 100) ##############\n",
    "v = learn_dict.matrix\n",
    "# сохраняем словарь на диск\n",
    "np.save(open('dictionary_500_100.npy', 'wb'), v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
