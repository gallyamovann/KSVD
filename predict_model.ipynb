{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXI-w8CF9N-N",
    "outputId": "ac406122-4fa6-4088-889c-ade51812c3dd"
   },
   "outputs": [],
   "source": [
    "# В случае, если ошибка с тензором\n",
    "!pip install tensorly\n",
    "!pip install opencv-python\n",
    "!pip install --force-reinstall -v \"tensorly==0.7.0\"\n",
    "!pip install --force-reinstall -v \"numpy==1.23.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.misc\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tucker, partial_tucker\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.image import extract_patches_2d, reconstruct_from_patches_2d\n",
    "from sklearn.linear_model import orthogonal_mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from typing import Type\n",
    "\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pursuit:\n",
    "    \"\"\"\n",
    "    Algorithms that inherit from this class are methods to solve problems of the like\n",
    "    \\min_A \\| DA - Y \\|_2 s.t. \\|A\\|_0 <= t.\n",
    "    Here, D is a given dictionary of size (n x K)\n",
    "    Y is a given matrix of size (n x N), where N is the number of samples\n",
    "    The Pursuit will return a matrix A of size (K x N).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dictionary, max_iter=False, tol=None, sparsity=None):\n",
    "        self.D = np.array(dictionary.matrix)\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.sparsity = sparsity\n",
    "        if (self.tol is None and self.sparsity is None) or (self.tol is not None and self.sparsity is not None):\n",
    "            raise ValueError(\"blub\")\n",
    "        self.data = None\n",
    "        self.alphas = []\n",
    "\n",
    "    def fit(self, Y):\n",
    "        return [], self.alphas\n",
    "    \n",
    "\n",
    "class OrthogonalMatchingPursuit(Pursuit):\n",
    "    \"\"\"\n",
    "    Wrapper for orthogonal_mp from scikit-learn\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, Y):\n",
    "        return orthogonal_mp(self.D, Y, n_nonzero_coefs=self.sparsity,\n",
    "                             tol=self.tol, precompute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "    \"\"\"\n",
    "    The Dictionary class is more or less a wrapper around the numpy array class. It holds a numpy ndarray in\n",
    "    the attribute `matrix` and adds some useful functions for it. The dictionary elements can be accessed\n",
    "    either by D.matrix[i,j] or directly through D[i,j].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, matrix):\n",
    "        self.matrix = np.array(matrix)\n",
    "        self.shape = matrix.shape\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.matrix[item]\n",
    "\n",
    "    def is_unitary(self):\n",
    "        \"\"\"\n",
    "        Checks whether the dictionary is unitary.\n",
    "        Returns:\n",
    "            True, if the dicitonary is unitary.\n",
    "        \"\"\"\n",
    "        n, K = self.shape\n",
    "        if n == K:\n",
    "            return np.allclose(np.dot(self.matrix.T, self.matrix), np.eye(n))\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_normalized(self):\n",
    "        \"\"\"\n",
    "        Checks wheter the dictionary is l2-normalized.\n",
    "        Returns:\n",
    "            True, if dictionary is l2-normalized.\n",
    "        \"\"\"\n",
    "        n, K = self.shape\n",
    "        return np.allclose([np.linalg.norm(self.matrix[:, i]) for i in range(K)], np.ones(K))\n",
    "\n",
    "\n",
    "    def mutual_coherence(self):\n",
    "        \"\"\"\n",
    "        Computes the dictionary's mutual coherence.\n",
    "        Returns:\n",
    "            Mutual coherence\n",
    "        \"\"\"\n",
    "        return np.max(self._mutual_coherence(self.matrix))\n",
    "\n",
    "    @staticmethod\n",
    "    def _mutual_coherence(D):\n",
    "        n, K = D.shape\n",
    "        mu = [np.abs(np.dot(D[:, i].T, D[:, j]) /\n",
    "                     (np.linalg.norm(D[:, i]) * np.linalg.norm(D[:, j])))\n",
    "              for i in range(K) for j in range(K) if j != i]\n",
    "        return mu\n",
    "\n",
    "    def to_img(self):\n",
    "        \"\"\"\n",
    "        Transforms the dictionary columns into patches and orders them for plotting purposes.\n",
    "        Returns:\n",
    "            Reordered dictionary matrix\n",
    "        \"\"\"\n",
    "        # dictionary dimensions\n",
    "        D = self.matrix\n",
    "        n, K = D.shape\n",
    "        M = self.matrix\n",
    "        # stretch atoms\n",
    "        for k in range(K):\n",
    "            M[:, k] = M[:, k] - (M[:, k].min())\n",
    "            if M[:, k].max():\n",
    "                M[:, k] = M[:, k] / D[:, k].max()\n",
    "\n",
    "        # patch size\n",
    "        n_r = int(np.sqrt(n))\n",
    "\n",
    "        # patches per row / column\n",
    "        K_r = int(np.sqrt(K))\n",
    "\n",
    "        # we need n_r*K_r+K_r+1 pixels in each direction\n",
    "        dim = n_r * K_r + K_r + 1\n",
    "        V = np.ones((dim, dim)) * np.min(D)\n",
    "\n",
    "        # compute the patches\n",
    "        patches = [np.reshape(D[:, i], (n_r, n_r)) for i in range(K)]\n",
    "\n",
    "        # place patches\n",
    "        for i in range(K_r):\n",
    "            for j in range(K_r):\n",
    "                V[j * n_r + 1 + j:(j + 1) * n_r + 1 + j, i * n_r + 1 + i:(i + 1) * n_r + 1 + i] = patches[\n",
    "                    i * K_r + j]\n",
    "        return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSVD:\n",
    "    \"\"\"\n",
    "    Implements the original K-SVD Algorithm as described in [1].\n",
    "    [1] Aharon, M., Elad, M. and Bruckstein, A., 2006. K-SVD: An algorithm for designing overcomplete dictionaries for\n",
    "        sparse representation. IEEE Transactions on signal processing, 54(11), p.4311.\n",
    "    Args:\n",
    "        dictionary: Initial dictionary of type sparselandtools.dictionaries.Dictionary\n",
    "        pursuit: Pursuit method to be used (any method from sparselandtools.pursuits)\n",
    "        sparsity: Target sparsity\n",
    "        noise_gain: Target noise_gain. If set, this will override the target sparsity\n",
    "        sigma: Signal or image noise standard deviation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dictionary: Dictionary, pursuit: Type[Pursuit], sparsity: int, noise_gain=None, sigma=None):\n",
    "        self.dictionary = Dictionary(dictionary.matrix)\n",
    "        self.alphas = None\n",
    "        self.pursuit = pursuit\n",
    "        self.sparsity = sparsity\n",
    "        self.noise_gain = noise_gain\n",
    "        self.sigma = sigma\n",
    "        self.original_image = None\n",
    "        self.sparsity_values = []\n",
    "        self.mses = []\n",
    "        self.ssims = []\n",
    "        self.psnrs = []\n",
    "        self.iter = None\n",
    "\n",
    "    def sparse_coding(self, Y: np.ndarray):\n",
    "        logging.info(\"Entering sparse coding stage...\")\n",
    "        if self.noise_gain and self.sigma:\n",
    "            p = self.pursuit(self.dictionary, tol=(self.noise_gain * self.sigma))\n",
    "        else:\n",
    "            p = self.pursuit(self.dictionary, sparsity=self.sparsity)\n",
    "        self.alphas = p.fit(Y)\n",
    "        logging.info(\"Sparse coding stage ended.\")\n",
    "\n",
    "    def dictionary_update(self, Y: np.ndarray):\n",
    "        # iterate rows\n",
    "        D = self.dictionary.matrix\n",
    "        n, K = D.shape\n",
    "        R = Y - D.dot(self.alphas)\n",
    "        for k in range(K):\n",
    "            logging.info(\"Updating column %s\" % k)\n",
    "            wk = np.nonzero(self.alphas[k, :])[0]\n",
    "            if len(wk) == 0:\n",
    "                continue\n",
    "            Ri = R[:,wk] + D[:,k,None].dot(self.alphas[None,k,wk])\n",
    "            U, s, Vh = np.linalg.svd(Ri)\n",
    "            D[:, k] = U[:, 0]\n",
    "            self.alphas[k, wk] = s[0] * Vh[0, :]\n",
    "            R[:, wk] = Ri - D[:,k,None].dot(self.alphas[None,k,wk])\n",
    "        self.dictionary = Dictionary(D)\n",
    "\n",
    "    def fit(self, Y: np.ndarray, iter: int):\n",
    "        for i in range(iter):\n",
    "            logging.info(\"Start iteration %s\" % (i + 1))\n",
    "            self.sparse_coding(Y)\n",
    "            self.dictionary_update(Y)\n",
    "        return self.dictionary, self.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_Mwprh9HiQY"
   },
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    core, factors = tucker(tl.tensor(image), rank=image.shape)\n",
    "    return factors[1]\n",
    "\n",
    "\n",
    "def get_matrix(y, image_path, patch_size):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    component = preprocess(image)\n",
    "    \n",
    "    # Извлеките все патчи изображения\n",
    "    patches = extract_patches_2d(component, (patch_size, patch_size))\n",
    "    \n",
    "    # Получите количество патчей\n",
    "    num_patches = patches.shape[0]\n",
    "    \n",
    "    # Рассчитайте стандартное отклонение (в качестве меры вариации) для каждого патча\n",
    "    std_devs = np.std(patches, axis=(1, 2))\n",
    "    \n",
    "    # Найдите индексы 5 патчей с наибольшей вариацией\n",
    "    top_indices = np.argsort(std_devs)[-5:]\n",
    "    \n",
    "    # Выберите 5 случайных патчей, которые не пересекаются с патчами с наибольшей вариацией\n",
    "    random_indices = []\n",
    "    while len(random_indices) < 5:\n",
    "        index = random.randint(0, num_patches - 1)\n",
    "        if index not in top_indices:\n",
    "            random_indices.append(index)\n",
    "    \n",
    "    # Получите случайные и патчи с наибольшей вариацией\n",
    "    random_patches = patches[random_indices]\n",
    "    top_patches = patches[top_indices]\n",
    "    \n",
    "    # Объедините случайные и патчи с наибольшей вариацией\n",
    "    selected_patches = np.concatenate((random_patches, top_patches), axis=0)\n",
    "    \n",
    "    # Преобразуйте патчи в нужный формат данных\n",
    "    data = selected_patches.reshape(selected_patches.shape[0], -1)\n",
    "    \n",
    "    # Обновите y с добавлением выбранных патчей\n",
    "    y = np.vstack([y, data])\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задать необходимые переменные \n",
    "\n",
    "# Директория с изображениями\n",
    "image_directory = 'images/'\n",
    "# Путь ко всем изображениям\n",
    "image_paths = glob(os.path.join(image_directory, '*.png'))\n",
    "\n",
    "# Если необходимо, то перемешать\n",
    "# shuffle(image_paths)\n",
    "\n",
    "# Размер патча\n",
    "patch_size = 10\n",
    "# Количество итераций обучения\n",
    "iterations = 1\n",
    "# Файл с временем цветения и изображением\n",
    "response_data = 'response.csv'\n",
    "# Название файла словаря\n",
    "dict_name = 'dictionary.npy'\n",
    "# Названия файла с фичами\n",
    "features_name = 'dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Слияние изображений\n",
    "y = np.zeros(patch_size * patch_size)\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    print('%d/%d %s' % (i, len(image_paths), image_path))\n",
    "    y = get_matrix(y, image_path, patch_size)\n",
    "\n",
    "y = np.delete(y, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuEZnnHvVXsK"
   },
   "outputs": [],
   "source": [
    "# Обучение словаря\n",
    "u, s, v = np.linalg.svd(y.T)\n",
    "initial_dictionary = Dictionary(u)\n",
    "ksvd = KSVD(initial_dictionary, OrthogonalMatchingPursuit, patch_size * patch_size)\n",
    "learn_dict, coeff = ksvd.fit(y.T, iterations)\n",
    "v = learn_dict.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отобразить полученный словарь\n",
    "plt.imshow(learn_dict.to_img(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление фич\n",
    "def get_features(x):\n",
    "    f_mic = []\n",
    "    f_mac = []\n",
    "    for i in range(x.shape[0]):\n",
    "        values = x[i]\n",
    "        values = np.abs(values[values!=0])\n",
    "        sigma, _, mean = sp.stats.lognorm.fit(values, loc=0)\n",
    "        f_mic.append(np.exp(mean + 0.5*sigma**2))\n",
    "        f_mac.append(values.shape[0])\n",
    "    return f_mic + f_mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем словарь на диск\n",
    "np.save(open(dict_name, 'wb'), v)\n",
    "v = np.load(open(dict_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание таблицы для записи фич\n",
    "df = pd.read_csv(response_data)\n",
    "images = df['image'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "image_paths = [image_directory+image for image in images]\n",
    "del df\n",
    "columns = ['image']\n",
    "for i in range(v.shape[1]):\n",
    "    columns.append('f%d_mic'%(i+1))\n",
    "for i in range(v.shape[1]):\n",
    "    columns.append('f%d_mac'%(i+1))\n",
    "columns.append('label')\n",
    "data = {column: [] for column in columns}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhUQoj9iQ4WM",
    "outputId": "41f13552-c10f-4e83-c4fb-dec974b849d9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Извлечение фич\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    y = np.zeros(patch_size * patch_size)\n",
    "    y = get_matrix(y, image_path, patch_size)\n",
    "    y = y.T\n",
    "    X = orthogonal_mp(v, y, n_nonzero_coefs=patch_size*patch_size)\n",
    "    features = get_features(X)\n",
    "    data = [images[i]] + features + [labels[i]]\n",
    "    data = {column: [datum] for column, datum in zip(columns, data)}\n",
    "    tmp = pd.DataFrame(data)\n",
    "    df = pd.concat([df, tmp], axis=0)\n",
    "    print('%d/%d %s' % (i, len(image_paths), image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение таблицы с фичами\n",
    "df.to_csv(features_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "df = pd.read_csv(features_name)\n",
    "columns = [column for column in df.columns if column not in ['image', 'label']]\n",
    "x = df[columns].to_numpy()\n",
    "y = df['label'].to_numpy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "model = make_pipeline(StandardScaler(), SVR(C=1000, epsilon=1, gamma=1))\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Максимальная ошибка прогнозирования\n",
    "max(abs(y_pred-y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя ошибка прогнозирования\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
