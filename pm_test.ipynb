{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e1778",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorly\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0395faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall -v \"tensorly==0.7.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall -v \"numpy==1.23.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396add7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Type\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.misc\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import tensorly as tl\n",
    "import numpy as np\n",
    "from sklearn.linear_model import orthogonal_mp\n",
    "from tensorly.decomposition import tucker, partial_tucker\n",
    "from sklearn.feature_extraction.image import extract_patches_2d, reconstruct_from_patches_2d\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pursuit:\n",
    "    \"\"\"\n",
    "    Algorithms that inherit from this class are methods to solve problems of the like\n",
    "    \\min_A \\| DA - Y \\|_2 s.t. \\|A\\|_0 <= t.\n",
    "    Here, D is a given dictionary of size (n x K)\n",
    "    Y is a given matrix of size (n x N), where N is the number of samples\n",
    "    The Pursuit will return a matrix A of size (K x N).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dictionary, max_iter=False, tol=None, sparsity=None):\n",
    "        self.D = np.array(dictionary.matrix)\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.sparsity = sparsity\n",
    "        if (self.tol is None and self.sparsity is None) or (self.tol is not None and self.sparsity is not None):\n",
    "            raise ValueError(\"blub\")\n",
    "        self.data = None\n",
    "        self.alphas = []\n",
    "\n",
    "    def fit(self, Y):\n",
    "        return [], self.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrthogonalMatchingPursuit(Pursuit):\n",
    "    \"\"\"\n",
    "    Wrapper for orthogonal_mp from scikit-learn\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, Y):\n",
    "        return orthogonal_mp(self.D, Y, n_nonzero_coefs=self.sparsity,\n",
    "                             tol=self.tol, precompute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a1a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "    \"\"\"\n",
    "    The Dictionary class is more or less a wrapper around the numpy array class. It holds a numpy ndarray in\n",
    "    the attribute `matrix` and adds some useful functions for it. The dictionary elements can be accessed\n",
    "    either by D.matrix[i,j] or directly through D[i,j].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, matrix):\n",
    "        self.matrix = np.array(matrix)\n",
    "        self.shape = matrix.shape\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.matrix[item]\n",
    "\n",
    "    def is_unitary(self):\n",
    "        \"\"\"\n",
    "        Checks whether the dictionary is unitary.\n",
    "        Returns:\n",
    "            True, if the dicitonary is unitary.\n",
    "        \"\"\"\n",
    "        n, K = self.shape\n",
    "        if n == K:\n",
    "            return np.allclose(np.dot(self.matrix.T, self.matrix), np.eye(n))\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_normalized(self):\n",
    "        \"\"\"\n",
    "        Checks wheter the dictionary is l2-normalized.\n",
    "        Returns:\n",
    "            True, if dictionary is l2-normalized.\n",
    "        \"\"\"\n",
    "        n, K = self.shape\n",
    "        return np.allclose([np.linalg.norm(self.matrix[:, i]) for i in range(K)], np.ones(K))\n",
    "\n",
    "\n",
    "    def mutual_coherence(self):\n",
    "        \"\"\"\n",
    "        Computes the dictionary's mutual coherence.\n",
    "        Returns:\n",
    "            Mutual coherence\n",
    "        \"\"\"\n",
    "        return np.max(self._mutual_coherence(self.matrix))\n",
    "\n",
    "    @staticmethod\n",
    "    def _mutual_coherence(D):\n",
    "        n, K = D.shape\n",
    "        mu = [np.abs(np.dot(D[:, i].T, D[:, j]) /\n",
    "                     (np.linalg.norm(D[:, i]) * np.linalg.norm(D[:, j])))\n",
    "              for i in range(K) for j in range(K) if j != i]\n",
    "        return mu\n",
    "\n",
    "    def to_img(self):\n",
    "        \"\"\"\n",
    "        Transforms the dictionary columns into patches and orders them for plotting purposes.\n",
    "        Returns:\n",
    "            Reordered dictionary matrix\n",
    "        \"\"\"\n",
    "        # dictionary dimensions\n",
    "        D = self.matrix\n",
    "        n, K = D.shape\n",
    "        M = self.matrix\n",
    "        # stretch atoms\n",
    "        for k in range(K):\n",
    "            M[:, k] = M[:, k] - (M[:, k].min())\n",
    "            if M[:, k].max():\n",
    "                M[:, k] = M[:, k] / D[:, k].max()\n",
    "\n",
    "        # patch size\n",
    "        n_r = int(np.sqrt(n))\n",
    "\n",
    "        # patches per row / column\n",
    "        K_r = int(np.sqrt(K))\n",
    "\n",
    "        # we need n_r*K_r+K_r+1 pixels in each direction\n",
    "        dim = n_r * K_r + K_r + 1\n",
    "        V = np.ones((dim, dim)) * np.min(D)\n",
    "\n",
    "        # compute the patches\n",
    "        patches = [np.reshape(D[:, i], (n_r, n_r)) for i in range(K)]\n",
    "\n",
    "        # place patches\n",
    "        for i in range(K_r):\n",
    "            for j in range(K_r):\n",
    "                V[j * n_r + 1 + j:(j + 1) * n_r + 1 + j, i * n_r + 1 + i:(i + 1) * n_r + 1 + i] = patches[\n",
    "                    i * K_r + j]\n",
    "        return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70db213",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSVD:\n",
    "    \"\"\"\n",
    "    Implements the original K-SVD Algorithm as described in [1].\n",
    "    [1] Aharon, M., Elad, M. and Bruckstein, A., 2006. K-SVD: An algorithm for designing overcomplete dictionaries for\n",
    "        sparse representation. IEEE Transactions on signal processing, 54(11), p.4311.\n",
    "    Args:\n",
    "        dictionary: Initial dictionary of type sparselandtools.dictionaries.Dictionary\n",
    "        pursuit: Pursuit method to be used (any method from sparselandtools.pursuits)\n",
    "        sparsity: Target sparsity\n",
    "        noise_gain: Target noise_gain. If set, this will override the target sparsity\n",
    "        sigma: Signal or image noise standard deviation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dictionary: Dictionary, pursuit: Type[Pursuit], sparsity: int, noise_gain=None, sigma=None):\n",
    "        self.dictionary = Dictionary(dictionary.matrix)\n",
    "        self.alphas = None\n",
    "        self.pursuit = pursuit\n",
    "        self.sparsity = sparsity\n",
    "        self.noise_gain = noise_gain\n",
    "        self.sigma = sigma\n",
    "        self.original_image = None\n",
    "        self.sparsity_values = []\n",
    "        self.mses = []\n",
    "        self.ssims = []\n",
    "        self.psnrs = []\n",
    "        self.iter = None\n",
    "\n",
    "    def sparse_coding(self, Y: np.ndarray):\n",
    "        logging.info(\"Entering sparse coding stage...\")\n",
    "        if self.noise_gain and self.sigma:\n",
    "            p = self.pursuit(self.dictionary, tol=(self.noise_gain * self.sigma))\n",
    "        else:\n",
    "            p = self.pursuit(self.dictionary, sparsity=self.sparsity)\n",
    "        self.alphas = p.fit(Y)\n",
    "        logging.info(\"Sparse coding stage ended.\")\n",
    "\n",
    "    def dictionary_update(self, Y: np.ndarray):\n",
    "        # iterate rows\n",
    "        D = self.dictionary.matrix\n",
    "        n, K = D.shape\n",
    "        R = Y - D.dot(self.alphas)\n",
    "        for k in range(K):\n",
    "            logging.info(\"Updating column %s\" % k)\n",
    "            wk = np.nonzero(self.alphas[k, :])[0]\n",
    "            if len(wk) == 0:\n",
    "                continue\n",
    "            Ri = R[:,wk] + D[:,k,None].dot(self.alphas[None,k,wk])\n",
    "            U, s, Vh = np.linalg.svd(Ri)\n",
    "            D[:, k] = U[:, 0]\n",
    "            self.alphas[k, wk] = s[0] * Vh[0, :]\n",
    "            R[:, wk] = Ri - D[:,k,None].dot(self.alphas[None,k,wk])\n",
    "        self.dictionary = Dictionary(D)\n",
    "\n",
    "    def fit(self, Y: np.ndarray, iter: int):\n",
    "        for i in range(iter):\n",
    "            logging.info(\"Start iteration %s\" % (i + 1))\n",
    "            self.sparse_coding(Y)\n",
    "            self.dictionary_update(Y)\n",
    "        return self.dictionary, self.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dafbdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    core, factors = partial_tucker(tl.tensor(image), rank=image.shape, modes=[0, 1, 2])\n",
    "    return factors[0]\n",
    "\n",
    "\n",
    "def get_matrix(y, image_path, patch_size):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    component = preprocess(image)\n",
    "    \n",
    "    # Extract all reference patches from the image\n",
    "    patches = extract_patches_2d(component, (patch_size, patch_size))\n",
    "    data = patches.reshape(patches.shape[0], -1)\n",
    "    y = np.vstack([y, data])\n",
    "    \n",
    "    return y\n",
    "  \n",
    "image_directory = 'images/images_squares_25'\n",
    "image_paths = glob(os.path.join(image_directory, '*.png'))\n",
    "from random import shuffle\n",
    "shuffle(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df064a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = image_paths[:50]\n",
    "patch_size = 4\n",
    "\n",
    "y = np.zeros(patch_size * patch_size)\n",
    "for image_path in image_paths:\n",
    "    y = get_matrix(y, image_path, patch_size)\n",
    "y = np.delete(y, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = y.T\n",
    "u, s, v = np.linalg.svd(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedcc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_dictionary = Dictionary(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c779ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_dictionary.is_unitary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "ksvd = KSVD(initial_dictionary, OrthogonalMatchingPursuit, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# второй аргумент - число итераций\n",
    "learn_dict, coeff = ksvd.fit(test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404d8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = learn_dict.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4613d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(learn_dict.to_img(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вычисление фич\n",
    "def get_features(x):\n",
    "    f_mic = []\n",
    "    f_mac = []\n",
    "    for i in range(x.shape[0]):\n",
    "        values = x[i]\n",
    "        values = np.abs(values[values!=0])\n",
    "        sigma, _, mean = sp.stats.lognorm.fit(values, loc=0)\n",
    "        f_mic.append(np.exp(mean + 0.5*sigma**2))\n",
    "        f_mac.append(values.shape[0])\n",
    "    return f_mic + f_mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем словарь на диск\n",
    "np.save(open('dictionary1.npy', 'wb'), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde3ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.load(open('dictionary1.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ceffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание таблицы для записи фич\n",
    "df = pd.read_csv('images/response.csv')\n",
    "images = df['image'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "image_paths = ['images/images_squares_25/'+image for image in images]\n",
    "del df\n",
    "image_paths = image_paths[:500]\n",
    "columns = ['image']\n",
    "for i in range(v.shape[1]):\n",
    "    columns.append('f%d_mic'%(i+1))\n",
    "for i in range(v.shape[1]):\n",
    "    columns.append('f%d_mac'%(i+1))\n",
    "columns.append('label')\n",
    "data = {column: [] for column in columns}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ffbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image_path in enumerate(image_paths):\n",
    "    y = np.zeros(patch_size * patch_size)\n",
    "    y = get_matrix(y, image_path, patch_size)\n",
    "    y = y.T\n",
    "    print(i)\n",
    "    X = orthogonal_mp(v, y, n_nonzero_coefs=8)\n",
    "    print(i)\n",
    "    features = get_features(X)\n",
    "    data = [images[i]] + features + [labels[i]]\n",
    "    data = {column: [datum] for column, datum in zip(columns, data)}\n",
    "    tmp = pd.DataFrame(data)\n",
    "    df = pd.concat([df, tmp], axis=0)\n",
    "    print('%d/%d %s' % (i, len(image_paths), image_path))\n",
    "\n",
    "df.to_csv('dataset2_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
